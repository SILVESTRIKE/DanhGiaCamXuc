import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from underthesea import word_tokenize
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import datetime

# ƒê·ªãnh nghƒ©a global bi·∫øn ƒë·ªÉ d√πng chung
aspects = [
    'FOOD#QUALITY', 'FOOD#PRICES', 'SERVICE#GENERAL', 'AMBIENCE#GENERAL',
    'LOCATION#GENERAL', 'RESTAURANT#GENERAL', 'FOOD#STYLE&OPTIONS',
    'RESTAURANT#PRICES', 'RESTAURANT#MISCELLANEOUS', 'DRINKS#QUALITY',
    'DRINKS#PRICES', 'DRINKS#STYLE&OPTIONS'
]

label_encoder = ['positive', 'negative', 'neutral']

# Load tokenizer
@st.cache_resource
def load_tokenizer():
    return AutoTokenizer.from_pretrained(".\models\phobert_restaurant_model")

# Load model
@st.cache_resource
def load_model():
    try:
        model = AutoModelForSequenceClassification.from_pretrained(".\models\phobert_restaurant_model")
        model.eval()
        return model
    except Exception:
        st.error("Kh√¥ng th·ªÉ load model. ƒê·∫£m b·∫£o file tr·ªçng s·ªë ƒë√£ ƒë∆∞·ª£c ƒë·∫∑t ƒë√∫ng th∆∞ m·ª•c.")
        return None

# Preprocess text
def preprocess_text(text):
    text = re.sub(r'[^\w\s]', '', text)
    text = word_tokenize(text, format="text").lower()
    return text

# Predict function
def predict(text, tokenizer, model):
    clean_text = preprocess_text(text)
    aspect_keywords = {
        'FOOD#QUALITY': ['ngon', 'd·ªü', 't∆∞∆°i', 'ch·∫•t l∆∞·ª£ng', 'v·ªã', 'th·ª©c ƒÉn', 'ƒë·ªì ƒÉn'],
        'FOOD#PRICES': ['gi√°', 'r·∫ª', 'ƒë·∫Øt', 'ti·ªÅn', 'chi ph√≠'],
        'SERVICE#GENERAL': ['ph·ª•c v·ª•', 'nh√¢n vi√™n', 'nhanh', 'ch·∫≠m', 'th√°i ƒë·ªô'],
        'AMBIENCE#GENERAL': ['kh√¥ng gian', 'view', 's·∫°ch', 'b·∫©n', 'tho√°ng', 'ƒë·∫πp'],
        'LOCATION#GENERAL': ['v·ªã tr√≠', 'ƒë·ªãa ƒëi·ªÉm', 'd·ªÖ t√¨m', 'xa', 'g·∫ßn'],
        'RESTAURANT#GENERAL': ['qu√°n', 'nh√† h√†ng', 't·ªïng th·ªÉ', 'tr·∫£i nghi·ªám'],
        'FOOD#STYLE&OPTIONS': ['m√≥n', 'menu', 'ƒëa d·∫°ng', 'l·ª±a ch·ªçn', 'ki·ªÉu'],
        'RESTAURANT#PRICES': ['gi√° c·∫£', 'chi ph√≠', 'h·ª£p l√Ω', 'ƒë·∫Øt ƒë·ªè'],
        'RESTAURANT#MISCELLANEOUS': ['g·ª≠i xe', 'v·ªá sinh', 'khƒÉn l·∫°nh', 'ti·ªán √≠ch'],
        'DRINKS#QUALITY': ['n∆∞·ªõc u·ªëng', 'tr√†', 'n∆∞·ªõc ng·ªçt', 'ƒë·ªì u·ªëng'],
        'DRINKS#PRICES': ['gi√°', 'r·∫ª', 'ƒë·∫Øt', 'n∆∞·ªõc u·ªëng'],
        'DRINKS#STYLE&OPTIONS': ['n∆∞·ªõc u·ªëng', 'menu', 'ƒëa d·∫°ng']
    }

    mentioned_aspects = [aspect for aspect, keywords in aspect_keywords.items() if any(keyword in clean_text for keyword in keywords)]
    if not mentioned_aspects:
        return "Kh√¥ng ph√°t hi·ªán kh√≠a c·∫°nh n√†o li√™n quan trong c√¢u."

    encoding = tokenizer.encode_plus(
        clean_text,
        add_special_tokens=True,
        max_length=128,
        return_token_type_ids=False,
        padding='max_length',
        truncation=True,
        return_attention_mask=True,
        return_tensors='pt'
    )

    input_ids = encoding['input_ids']
    attention_mask = encoding['attention_mask']

    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits.view(-1, len(aspects), 3)
    probs = torch.nn.functional.softmax(logits, dim=2)[0]
    preds = torch.argmax(probs, dim=1)

    results = {}
    for i, aspect in enumerate(aspects):
        if aspect in mentioned_aspects:
            label_id = preds[i].item()
            label_probs = probs[i].tolist()
            results[aspect] = {
                "label": label_encoder[label_id],
                "probs": label_probs
            }
    return results, len(text), input_ids.shape[1], len(clean_text.split()), datetime.datetime.now()

# Kh·ªüi t·∫°o session_state
if 'history' not in st.session_state:
    st.session_state.history = []

if 'selected_history_index' not in st.session_state:
    st.session_state.selected_history_index = None

st.set_page_config(page_title="Ph√¢n t√≠ch c·∫£m x√∫c nh√† h√†ng", layout="wide")
tabs = st.tabs(["üîç Nh·∫≠p li·ªáu & K·∫øt qu·∫£", "üìà Bi·ªÉu ƒë·ªì", "üìú L·ªãch s·ª≠", "üìä Th·ªëng k√™"])

with tabs[0]:
    st.title("üîç Nh·∫≠p li·ªáu & K·∫øt qu·∫£")

    if st.session_state.selected_history_index is not None:
        entry = st.session_state.history[st.session_state.selected_history_index]
        text_input = entry['text']
        results = entry['result']
        char_len = entry['char_len']
        token_len = entry['token_len']
        word_count = entry['word_count']
        timestamp = entry['time']
        st.session_state.selected_history_index = None
    else:
        text_input = st.text_area("Nh·∫≠p ƒë√°nh gi√° c·ªßa b·∫°n:", height=150)
        results = None

    if st.button("Ph√¢n t√≠ch", key="analyze") and results is None:
        if not text_input.strip():
            st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung ƒë·ªÉ ph√¢n t√≠ch.")
        else:
            tokenizer = load_tokenizer()
            model = load_model()

            prediction = predict(text_input, tokenizer, model)
            if isinstance(prediction, str):
                st.warning(prediction)
            else:
                results, char_len, token_len, word_count, timestamp = prediction

                st.session_state.history.append({
                    "text": text_input,
                    "result": results,
                    "char_len": char_len,
                    "token_len": token_len,
                    "word_count": word_count,
                    "time": timestamp
                })

    if results:
        st.subheader("K·∫øt qu·∫£ ph√¢n t√≠ch")
        rows = []
        for aspect, detail in results.items():
            rows.append([aspect, detail['label'], *detail['probs']])
        df = pd.DataFrame(rows, columns=["Kh√≠a c·∫°nh", "C·∫£m x√∫c", "T√≠ch c·ª±c", "Ti√™u c·ª±c", "Trung t√≠nh"])
        st.dataframe(df)

        final_counts = df['C·∫£m x√∫c'].value_counts()
        final_sentiment = final_counts.idxmax() if not final_counts.empty else "neutral"
        confidence = df[["T√≠ch c·ª±c", "Ti√™u c·ª±c", "Trung t√≠nh"]].max(axis=1).mean()
        score = round(confidence * 10, 2)

        color = {"POSITIVE": "green", "NEGATIVE": "red", "NEUTRAL": "gray"}.get(final_sentiment.upper(), "black")
        st.markdown(f'<div style="color: {color};">T·ªïng k·∫øt: ƒê√°nh gi√° to√†n c√¢u l√† <b>{final_sentiment.upper()}</b> v·ªõi ƒë·ªô t·ª± tin kho·∫£ng <b>{confidence:.2f}</b>, ƒëi·ªÉm ƒë√°nh gi√° ∆∞·ªõc l∆∞·ª£ng: <b>{score}/10</b></div>', unsafe_allow_html=True)
        st.markdown(f"**ƒê·ªô d√†i vƒÉn b·∫£n:** {char_len} k√Ω t·ª± | {word_count} t·ª´ | {token_len} token sau m√£ h√≥a")

with tabs[1]:
    st.title("üìà Bi·ªÉu ƒë·ªì t·ªïng quan")
    if not st.session_state.history:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì.")
    else:
        latest = st.session_state.history[-1]
        df = pd.DataFrame([
            [aspect, detail['label'], *detail['probs']] for aspect, detail in latest['result'].items()
        ], columns=["Kh√≠a c·∫°nh", "C·∫£m x√∫c", "T√≠ch c·ª±c", "Ti√™u c·ª±c", "Trung t√≠nh"])

        st.markdown(f"**ƒê·ªô d√†i vƒÉn b·∫£n:** {latest['char_len']} k√Ω t·ª± | {latest['word_count']} t·ª´ | {latest['token_len']} token")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### üéØ T·ª∑ l·ªá c·∫£m x√∫c")
            sentiments = df['C·∫£m x√∫c'].value_counts()
            fig1, ax1 = plt.subplots()
            ax1.pie(sentiments, labels=sentiments.index, autopct='%1.1f%%', colors=sns.color_palette('pastel'))
            st.pyplot(fig1)

        with col2:
            st.markdown("### üß© Bi·ªÉu ƒë·ªì kh√≠a c·∫°nh")
            fig2, ax2 = plt.subplots()
            sns.countplot(x="C·∫£m x√∫c", data=df, palette='viridis', ax=ax2)
            st.pyplot(fig2)

        col3, col4 = st.columns(2)
        with col3:
            st.markdown("### üß™ Ph√¢n ph·ªëi token")
            token_lengths = [entry['token_len'] for entry in st.session_state.history]
            fig3, ax3 = plt.subplots()
            sns.histplot(token_lengths, bins=10, kde=True, ax=ax3)
            st.pyplot(fig3)

        with col4:
            st.markdown("### üìâ Bi·ªÉu ƒë·ªì x√°c su·∫•t trung b√¨nh")
            mean_probs = df[["T√≠ch c·ª±c", "Ti√™u c·ª±c", "Trung t√≠nh"]].mean()
            fig4, ax4 = plt.subplots()
            sns.barplot(x=mean_probs.index, y=mean_probs.values, palette='pastel', ax=ax4)
            st.pyplot(fig4)

with tabs[2]:
    st.title("üìú L·ªãch s·ª≠ t∆∞∆°ng t√°c")
    if st.button("üóëÔ∏è X√≥a to√†n b·ªô l·ªãch s·ª≠"):
        st.session_state.history = []
        st.success("ƒê√£ x√≥a l·ªãch s·ª≠.")
        st.experimental_rerun()

    for idx, entry in enumerate(reversed(st.session_state.history)):
        i = len(st.session_state.history) - 1 - idx
        col1, col2 = st.columns([8, 2])
        with col1:
            if st.button(f"Xem l·∫°i [{entry['time'].strftime('%Y-%m-%d %H:%M:%S')}] {entry['text'][:40]}...", key=f"load_{i}"):
                st.session_state.selected_history_index = i
                st.experimental_rerun()
        with col2:
            if st.button("Xo√°", key=f"delete_{i}"):
                st.session_state.history.pop(i)
                st.experimental_rerun()

with tabs[3]:
    st.title("üìä Th·ªëng k√™ t·ªïng h·ª£p")
    if not st.session_state.history:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ th·ªëng k√™.")
    else:
        total = len(st.session_state.history)
        st.metric("T·ªïng s·ªë l∆∞·ª£t ƒë√°nh gi√°", total)

        times = [item['time'] for item in st.session_state.history]
        sentiments_all = []
        for item in st.session_state.history:
            for aspect, detail in item['result'].items():
                sentiments_all.append({"time": item['time'], "label": detail['label']})

        df_all = pd.DataFrame(sentiments_all)
        df_all['date'] = df_all['time'].dt.date

        st.markdown("### üìÖ Bi·ªÉu ƒë·ªì c·∫£m x√∫c theo th·ªùi gian")
        fig_time, ax_time = plt.subplots()
        sns.countplot(x="date", hue="label", data=df_all, ax=ax_time)
        ax_time.set_ylabel("S·ªë l∆∞·ª£t")
        st.pyplot(fig_time)

        st.markdown("### ‚öôÔ∏è Th√¥ng s·ªë m√¥ h√¨nh")
        st.markdown("- M√¥ h√¨nh: `phobert-base`")
        st.markdown(f"- T·ªïng s·ªë kh√≠a c·∫°nh: {len(aspects)}")
        st.markdown(f"- Nh√£n: {', '.join(label_encoder)}")
        st.markdown(f"- Th·ªùi gian ph√¢n t√≠ch ƒë·∫ßu ti√™n: {min(times).strftime('%Y-%m-%d %H:%M:%S')}")
        st.markdown(f"- Th·ªùi gian g·∫ßn nh·∫•t: {max(times).strftime('%Y-%m-%d %H:%M:%S')}")
